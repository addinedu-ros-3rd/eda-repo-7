{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from user_agent import generate_user_agent\n",
    "from tqdm import tqdm\n",
    "import openpyxl\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wb = openpyxl.load_workbook(f'../data/crawling_all_drama_20230914.xlsx')\n",
    "except:\n",
    "    wb = openpyxl.Workbook()\n",
    "w1 = wb.worksheets[0]\n",
    "\n",
    "w1.cell(1, 2).value = 'drama_id'\n",
    "w1.cell(1, 3).value = 'drama_name'\n",
    "w1.cell(1, 4).value = 'kor_name'\n",
    "w1.cell(1, 5).value = 'year'\n",
    "w1.cell(1, 6).value = 'director'\n",
    "w1.cell(1, 7).value = 'screenwriter'\n",
    "w1.cell(1, 8).value = 'country'\n",
    "w1.cell(1, 9).value = 'type'\n",
    "w1.cell(1, 10).value = 'tot_eps'\n",
    "w1.cell(1, 11).value = 'duration'\n",
    "w1.cell(1, 12).value = 'start_dt'\n",
    "w1.cell(1, 13).value = 'end_dt'\n",
    "w1.cell(1, 14).value = 'aired_on'\n",
    "w1.cell(1, 15).value = 'org_net'\n",
    "w1.cell(1, 16).value = 'content_rt'\n",
    "w1.cell(1, 17).value = 'synopsis'\n",
    "w1.cell(1, 18).value = 'rank'\n",
    "w1.cell(1, 19).value = 'pop'\n",
    "w1.cell(1, 20).value = 'genres'\n",
    "w1.cell(1, 21).value = 'watchers'\n",
    "w1.cell(1, 22).value = 'score'\n",
    "w1.cell(1, 23).value = 'evaluators'\n",
    "wb.save(f'../data/crawling_all_drama_20230914.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 85/92 [01:40<00:08,  1.18s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N/A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\whghd\\Desktop\\code\\proj\\k_drama\\proj_1_kdrama\\src\\mydramalist_crawling.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, href \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tmp_id, tmp_href):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m     \u001b[39mif\u001b[39;00m w1\u001b[39m.\u001b[39mcell(cnt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m         datas \u001b[39m=\u001b[39m search_drama(cnt, \u001b[39mid\u001b[39m, href)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m         write_data(w1, datas)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m         wb\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data/crawling_all_drama_20230914.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\whghd\\Desktop\\code\\proj\\k_drama\\proj_1_kdrama\\src\\mydramalist_crawling.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# 평점, 기여자수, 순위, 인기순위, 시청자수\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m statistics_soup \u001b[39m=\u001b[39m side_soup[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfindAll(\u001b[39m\"\u001b[39m\u001b[39mli\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(statistics_soup[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m][:\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mstrip())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m evaluators \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(re\u001b[39m.\u001b[39msearch(\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*,?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\"\u001b[39m, statistics_soup[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext)\u001b[39m.\u001b[39mgroup()\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/whghd/Desktop/code/proj/k_drama/proj_1_kdrama/src/mydramalist_crawling.ipynb#W2sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m rank \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(statistics_soup[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'N/A'"
     ]
    }
   ],
   "source": [
    "header = {'User-Agent': generate_user_agent()}\n",
    "\n",
    "# 드라마 링크, ID 받아서 리턴하는 함수\n",
    "def get_dramas(page):\n",
    "    tmp_id = []\n",
    "    tmp_href = []\n",
    "\n",
    "    url = \"https://mydramalist.com/search?adv=titles&ty=68&co=3&re=2015,2023&st=3&so=relevance&page=\" + str(page)\n",
    "    req = Request(url, headers=header)\n",
    "    res = urlopen(req)\n",
    "    soup = BeautifulSoup(res.read(), 'html.parser')\n",
    "\n",
    "    drama_box = soup.find(\"div\", \"m-t nav-active-border b-primary\")\n",
    "    dramas = drama_box.findAll(\"div\")\n",
    "    for drama in dramas:\n",
    "        try:\n",
    "            drama_id = re.search(\"mdl-\\d+\", drama['id']).group().split(\"-\")[1]\n",
    "            if drama_id != None:\n",
    "                tmp_id.append(drama_id)\n",
    "                drama_href = drama.find('div', \"col-xs-9 row-cell content\").find('a')['href']\n",
    "                tmp_href.append(drama_href)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return tmp_id, tmp_href\n",
    "\n",
    "# 드라마 상세페이지에서 각종 정보 리턴하는 함수\n",
    "def search_drama(idx, id, search_href):\n",
    "    drama_id, drama_name, kor_name, year, director, screenwriter, country, type, tot_eps, duration\\\n",
    "        , start_dt, end_dt, aired_on, org_net, content_rt, synopsis, rank, pop, genres, watchers\\\n",
    "        , score, evaluators = [\"\"] * 22\n",
    "    type = \"Drama\"\n",
    "\n",
    "    drama_url = \"https://mydramalist.com\" + search_href\n",
    "    req = Request(drama_url, headers=header)\n",
    "    res = urlopen(req)\n",
    "    drama_soup = BeautifulSoup(res.read(), 'html.parser')\n",
    "\n",
    "    side_soup = drama_soup.findAll(\"ul\", \"list m-b-0\")\n",
    "\n",
    "    # 이름, 나라, 에피소드수, 방영시작일, 종료일\n",
    "    detail_soup = side_soup[0].findAll(\"li\")\n",
    "    drama_name = detail_soup[0].find(\"span\").text\n",
    "    country = detail_soup[1].text.split(\":\")[1].strip()\n",
    "    tot_eps = int(detail_soup[2].text.split(\":\")[1].strip())\n",
    "    aired_dt = detail_soup[3].text.split(\":\")[1].strip().split(\"-\")\n",
    "    if len(aired_dt) ==2:\n",
    "        start_dt = aired_dt[0].strip()\n",
    "        end_dt = aired_dt[1].strip()\n",
    "    else:\n",
    "        start_dt = aired_dt[0].strip()\n",
    "\n",
    "    # 방영요일, 중계플랫폼, 플레이타임, 제한연령\n",
    "    for li in detail_soup[4:]:\n",
    "        tp = li.find(\"b\").text\n",
    "        if tp == \"Aired On:\":\n",
    "            aired_on = li.text.split(\":\")[1].strip()\n",
    "        if tp == \"Original Network:\":\n",
    "            org_net = \"[\" + li.text.split(\":\")[1].strip() + \"]\"\n",
    "        if tp == \"Duration:\":\n",
    "            duration = li.text.split(\":\")[1].strip().replace(\"min.\", \"\").split(\"hr.\")\n",
    "            if len(duration) == 2:\n",
    "                duration = int(duration[0]) * 60 + int(duration[1])\n",
    "            else:\n",
    "                duration = int(duration[0])\n",
    "            duration *= 60  # 초단위 변환\n",
    "        if tp == \"Content Rating:\":\n",
    "            content_rt = li.text.split(\":\")[1].strip()\n",
    "\n",
    "    # 평점, 기여자수, 순위, 인기순위, 시청자수\n",
    "    statistics_soup = side_soup[1].findAll(\"li\")\n",
    "    score = float(statistics_soup[0].text.split(\":\")[1][:4].strip())\n",
    "    evaluators = int(re.search(\"\\d*,?\\d+\", statistics_soup[0].find(\"span\").text).group().replace(',', ''))\n",
    "    rank = int(statistics_soup[1].text.split(\":\")[1].replace(\"#\", \"\"))\n",
    "    pop = int(statistics_soup[2].text.split(\":\")[1].replace(\"#\", \"\"))\n",
    "    watchers = int(statistics_soup[3].text.split(\":\")[1].replace(\",\", \"\"))\n",
    "\n",
    "    # 한국명, 장르, 작가, 감독\n",
    "    infos = drama_soup.find(\"div\", \"show-detailsxss\")\n",
    "    kor_name = infos.find(\"li\", \"list-item p-a-0\").text.split(\":\")[1].strip()\n",
    "    try:\n",
    "        genres = infos.find(\"li\", \"list-item p-a-0 show-genres\").findAll(\"a\")\n",
    "    except:\n",
    "        genres = []\n",
    "    \n",
    "    screenwriter = []\n",
    "    director = []\n",
    "    info_li = infos.findAll(\"li\", \"list-item p-a-0\")\n",
    "    for li in info_li[2:]:\n",
    "        tp = li.find(\"b\").text\n",
    "        if tp == \"Screenwriter:\":\n",
    "            for a in li.findAll(\"a\"):\n",
    "                screenwriter.append(a.text)\n",
    "        if tp == \"Director:\":\n",
    "            for a in li.findAll(\"a\"):\n",
    "                director.append(a.text)\n",
    "        if tp == \"Screenwriter & Director:\":\n",
    "            for a in li.findAll(\"a\"):\n",
    "                director.append(a.text)\n",
    "                screenwriter.append(a.text)\n",
    "\n",
    "    # 작가, 감독, 장르 리스트 전처리\n",
    "    screenwriter = \"[\" + \",\".join(screenwriter) + \"]\"\n",
    "    director = \"[\" + \",\".join(director) + \"]\"\n",
    "    \n",
    "    genre_list = []\n",
    "    for genre in genres:\n",
    "        genre_list.append(genre.text)\n",
    "    genre_list = \", \".join(genre_list)\n",
    "    \n",
    "    # 시놉시스\n",
    "    synopsis_soup = drama_soup.find(\"div\", \"show-synopsis\").findAll(\"span\")\n",
    "    for s in synopsis_soup:\n",
    "        synopsis += s.text\n",
    "\n",
    "    # 방영시작일, 종료일 전처리\n",
    "    try:\n",
    "        year = datetime.strptime(start_dt, \"%b %d, %Y\").year\n",
    "    except:\n",
    "        year = \"\"\n",
    "\n",
    "    drama_id = id\n",
    "\n",
    "    return [idx, drama_id, drama_name, kor_name, year, director, screenwriter, country, type, tot_eps\n",
    "            , duration, start_dt, end_dt, aired_on, org_net, content_rt, synopsis, rank, pop\n",
    "            , genre_list, watchers, score, evaluators]\n",
    "\n",
    "# 엑셀 저장\n",
    "def write_data(w1, datas):\n",
    "    pos = datas[0]\n",
    "    w1.cell(pos+1, 1).value = pos\n",
    "    for i, data in enumerate(datas):\n",
    "        w1.cell(pos+1, i+1).value = data\n",
    "\n",
    "try:\n",
    "    wb = openpyxl.load_workbook(f'../data/crawling_all_drama_20230914.xlsx')\n",
    "except:\n",
    "    wb = openpyxl.Workbook()\n",
    "w1 = wb.worksheets[0]\n",
    "\n",
    "cnt = 1\n",
    "for i in tqdm(range(1, 93)):\n",
    "    tmp_id, tmp_href = get_dramas(i)\n",
    "\n",
    "    for id, href in zip(tmp_id, tmp_href):\n",
    "        if w1.cell(cnt+1, 1).value == None:\n",
    "            datas = search_drama(cnt, id, href)\n",
    "            write_data(w1, datas)\n",
    "            wb.save(f'../data/crawling_all_drama_20230914.xlsx')\n",
    "        cnt += 1\n",
    "        # time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스코어 없는 것부터는 데이터 의미 없다고 생각 -> 크롤링 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 아래는 테스트용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 40257, 'Move to Heaven', '무브 투 헤븐', 2021, '[Kim Sung Ho]', '[Yoon Ji Ryun]', 'South Korea', 'Drama', 10, 3120, 'May 14, 2021', '', 'Friday', '[Netflix]', '18+ Restricted (violence & profanity)', 'Han Geu Roo is an autistic 20-year-old. He works for his father’s business “Move To Heaven,” a company that specializes in crime scene cleanup, where they also collect and arrange items left by deceased people, and deliver them to the bereaved family.\\n\\nWhen Geu Roo\\'s father dies, Geu Roo\\'s guardianship passes to his uncle, ex-convict Cho Sang Gu, who is a martial arts fighter in underground matches. Per the father\\'s will, Sang Gu must care for and work with Geu Roo in “Move To Heaven” for three months to gain full guardianship and claim the inheritance. Eying money, Sang Gu agrees to the conditions and moves in.\\n\\n(Source: MyDramaList)\\n\\n~~ Adapted from the nonfiction essay \"Things Left Behind\" by professional trauma cleaner Kim Sae Byul. Gu must care for and work with Geu Roo in “Move To Heaven” for three months to gain full guardianship and claim the inheritance. Eying money, Sang Gu agrees to the conditions and moves in.\\n\\n(Source: MyDramaList)\\n\\n~~ Adapted from the nonfiction essay \"Things Left Behind\" by professional trauma cleaner Kim Sae Byul.', 10, 84, 'Life, Drama', 75792, 9.2, 38102]\n"
     ]
    }
   ],
   "source": [
    "# def search_drama(idx, id, search_href):\n",
    "#     drama_id, drama_name, kor_name, year, director, screenwriter, country, type, tot_eps, duration\\\n",
    "#         , start_dt, end_dt, aired_on, org_net, content_rt, synopsis, rank, pop, genres, watchers\\\n",
    "#         , score, evaluators = [\"\"] * 22\n",
    "#     type = \"Drama\"\n",
    "\n",
    "#     drama_url = \"https://mydramalist.com\" + search_href\n",
    "#     req = Request(drama_url, headers=header)\n",
    "#     res = urlopen(req)\n",
    "#     drama_soup = BeautifulSoup(res.read(), 'html.parser')\n",
    "\n",
    "#     side_soup = drama_soup.findAll(\"ul\", \"list m-b-0\")\n",
    "\n",
    "#     detail_soup = side_soup[0].findAll(\"li\")\n",
    "#     drama_name = detail_soup[0].find(\"span\").text\n",
    "#     country = detail_soup[1].text.split(\":\")[1].strip()\n",
    "#     tot_eps = int(detail_soup[2].text.split(\":\")[1].strip())\n",
    "#     aired_dt = detail_soup[3].text.split(\":\")[1].strip().split(\"-\")\n",
    "#     if len(aired_dt) ==2:\n",
    "#         start_dt = aired_dt[0].strip()\n",
    "#         end_dt = aired_dt[1].strip()\n",
    "#     else:\n",
    "#         start_dt = aired_dt[0].strip()\n",
    "#     aired_on = detail_soup[4].text.split(\":\")[1].strip()\n",
    "\n",
    "\n",
    "#     for li in detail_soup[5:]:\n",
    "#         tp = li.find(\"b\").text\n",
    "#         if tp == \"Original Network:\":\n",
    "#             org_net = \"[\" + li.text.split(\":\")[1].strip() + \"]\"\n",
    "#         if tp == \"Duration:\":\n",
    "#             duration = li.text.split(\":\")[1].strip().replace(\"min.\", \"\").split(\"hr.\")\n",
    "#             if len(duration) == 2:\n",
    "#                 duration = int(duration[0]) * 60 + int(duration[1])\n",
    "#             else:\n",
    "#                 duration = int(duration[0])\n",
    "#             duration *= 60\n",
    "#         if tp == \"Content Rating:\":\n",
    "#             content_rt = li.text.split(\":\")[1].strip()\n",
    "\n",
    "#     statistics_soup = side_soup[1].findAll(\"li\")\n",
    "#     score = float(statistics_soup[0].text.split(\":\")[1][:4].strip())\n",
    "#     evaluators = int(re.search(\"\\d*,?\\d+\", statistics_soup[0].find(\"span\").text).group().replace(',', ''))\n",
    "#     rank = int(statistics_soup[1].text.split(\":\")[1].replace(\"#\", \"\"))\n",
    "#     pop = int(statistics_soup[2].text.split(\":\")[1].replace(\"#\", \"\"))\n",
    "#     watchers = int(statistics_soup[3].text.split(\":\")[1].replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "#     infos = drama_soup.find(\"div\", \"show-detailsxss\")\n",
    "#     kor_name = infos.find(\"li\", \"list-item p-a-0\").text.split(\":\")[1].strip()\n",
    "#     genres = infos.find(\"li\", \"list-item p-a-0 show-genres\").findAll(\"a\")\n",
    "\n",
    "#     screenwriter = []\n",
    "#     director = []\n",
    "#     info_li = infos.findAll(\"li\", \"list-item p-a-0\")\n",
    "#     for li in info_li[2:]:\n",
    "#         tp = li.find(\"b\").text\n",
    "#         if tp == \"Screenwriter:\":\n",
    "#             for a in li.find(\"a\"):\n",
    "#                 screenwriter.append(a.text)\n",
    "#         if tp == \"Director:\":\n",
    "#             for a in li.find(\"a\"):\n",
    "#                 director.append(a.text)\n",
    "#         if tp == \"Screenwriter & Director:\":\n",
    "#             for a in li.find(\"a\"):\n",
    "#                 director.append(a.text)\n",
    "#                 screenwriter.append(a.text)\n",
    "#     screenwriter = \"[\" + \",\".join(screenwriter) + \"]\"\n",
    "#     director = \"[\" + \",\".join(director) + \"]\"\n",
    "    \n",
    "#     genre_list = []\n",
    "#     for genre in genres:\n",
    "#         genre_list.append(genre.text)\n",
    "#     genre_list = \", \".join(genre_list)\n",
    "\n",
    "#     watchers = drama_soup.findAll(\"div\", \"box clear hidden-sm-down\")[-1].findAll(\"li\", \"list-item p-a-0\")[-2].text\n",
    "#     watchers = watchers.split(\":\")[1].split(\",\")\n",
    "#     watchers = int(\"\".join(watchers))\n",
    "    \n",
    "#     synopsis_soup = drama_soup.find(\"div\", \"show-synopsis\").findAll(\"span\")\n",
    "#     for s in synopsis_soup:\n",
    "#         synopsis += s.text\n",
    "\n",
    "#     year = datetime.strptime(start_dt, \"%b %d, %Y\").year\n",
    "\n",
    "#     drama_id = id\n",
    "\n",
    "#     return [idx, drama_id, drama_name, kor_name, year, director, screenwriter, country, type, tot_eps\n",
    "#             , duration, start_dt, end_dt, aired_on, org_net, content_rt, synopsis, rank, pop\n",
    "#             , genre_list, watchers, score, evaluators]\n",
    "\n",
    "# print(search_drama(1, 40257, \"/49231-move-to-heaven\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
